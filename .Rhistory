# through time t is exp(-(cumulative hazard to t)),
# so survival quantile q occurs at cumulative
# hazard -log(1-q). Sampling is trivial for the
# control arm:
T0 <- invCumHaz0(-log(1-q))
invCumHaz0 <- function(CH) CH/lam
# Let's start with exponential, and uniform censoring
lam <- 2.1
cumHaz0 <- function(t) lam*t
invCumHaz0 <- function(CH) CH/lam
cumHaz0(1)
cumHaz0(10)
cumHaz0(100000)
invCumHaz0(100000)
invCumHaz0(1)
invCumHaz0(10)
# We can sample survival for both arms using
# invCumHaz0. Recall that probability of surviving
# through time t is exp(-(cumulative hazard to t)),
# so survival quantile q occurs at cumulative
# hazard -log(1-q). Sampling is trivial for the
# control arm:
T0 <- invCumHaz0(-log(1-q))
T0
beta <- 0.5
# Allocation to groups (z=1 means treatment)
z <- as.numeric(runif(n) < p)
TT <- ifelse(z == 1, T1, T0)
# The same is true for the treatment arm -- quantile
# q is cumulative hazard -log(1-q). Since
# cumulative hazard in the treatment arm is exp(beta)
# times the cumulative hazard in the control arm,
# the time at which the treatment arm achieves
# cumulative hazard CH equals the time at which the
# control arm reaches cumulative hazard CH/exp(beta).
T1 <- invCumHaz0(-log(1-q)/exp(beta))
TT <- ifelse(z == 1, T1, T0)
# Censoring time
C <- rG(n)
rG <- function(n) runif(n, 0, cmax)
rG(1)
cmax <- Inf
rG(1)
n
rG(100)
cmax <- 101
rG(100)
?runif
Tmax <- 100
rG <- function(n, Tmax) runif(n, 0, Tmax)
# Censoring time
C <- rG(n, Tmax)
C
# OK, let's build up a data frame with this
# information (delta indicates whether this is an
# observed event or just a censoring)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
dat <- fulldat[fulldat$delta == 1,]
View(dat)
TT
Tmax <- 1
C <- rG(n, Tmax)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
dat <- fulldat[fulldat$delta == 1,]
Tmax <- 0.5
C<- rG(n,Tmax)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
dat <- fulldat[fulldat$delta == 1,]
Tmax <- 0.2
C <- rG(n, Tmax)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
dat <- fulldat[fulldat$delta == 1,]
View(fulldat)
Tmax <- 0.5
C <- rG(n, Tmax)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
?pmin
muTilde <- function(beta) {
dat$Y1*exp(beta) / (dat$Y1*exp(beta) + dat$Y0)
}
betaHat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(betaHat)*(1-muTilde(betaHat)))
betaHat
sig
library(survival)
library(survminer)
mod <- coxph(Surv(obs, delta+1) ~ z, data=fulldat)
betaHat
summary(mod)$coefficients[1,"coef"]
sqrt(1/sig)
summary(mod)$coefficients[1,"se(coef)"]
muTilde <- function(beta) {
fulldat$Y1*exp(beta) / (fulldat$Y1*exp(beta) + fulldat$Y0)
}
betaHat <- uniroot(function(beta) {
sapply(beta, function(b) sum(fulldat$z)-sum(muTilde(b)))
}, interval=c(-10, 10), tol=1e-10)$root
betaHat
?coxph
View(dat)
0.4
t <- 0.4
dat.t <- fulldat %>% filter(obs < t)
library(dplyr, lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
dat.t <- fulldat %>% filter(obs < t)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z, C = C, TT = TT)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
dat.t <- fulldat %>% filter(t < Tmax - C + TT)
View(dat.t)
C
T-t
C <- rG(n, Tmax)
Tmax
t
C
T-t
Tmax-t
C-Tmax+t
C-Tmax + t
C
C.t <- pmin(C, max(C-Tmax + t,0))
C.t
max(C-Tmax + t,0)
pmax(C-Tmax + t,0)
C.t <- pmin(C, pmax(C-Tmax + t,0))
C.t
max(pmax(C-Tmax + t,0))
max(C.t)
# Estimates the given a data frame and a parameter beta
muTilde <- function(dat, beta) {
dat$Y1*exp(beta) / (dat$Y1*exp(beta) + dat$Y0)
}
# Returns coxph estimate and sig
betaHat <- function(dat, beta){
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(betaHat)*(1-muTilde(betaHat)))  #what is sig?
c("coef"=betaHat, "sig"=sig)
}
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
beta.est <- betaHat(dat.t)
betaHat <- function(dat, beta){
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(dat, b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(betaHat)*(1-muTilde(betaHat)))  #what is sig?
c("coef"=betaHat, "sig"=sig)
}
beta.est <- betaHat(dat.t)
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat.t$z)-sum(muTilde(dat.t, b)))
}, interval=c(-10, 10), tol=1e-10)$root
hat
beta
# Returns coxph estimate and sig
betaHat <- function(dat, beta){
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(dat, b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(dat, betaHat)*(1-muTilde(dat, betaHat)))  #what is sig?
c("coef"=betaHat, "sig"=sig)
}
beta.est <- betaHat(dat.t)
betaHat <- function(dat){
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(dat, b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(dat, betaHat)*(1-muTilde(dat, betaHat)))  #what is sig?
c("coef"=betaHat, "sig"=sig)
}
beta.est <- betaHat(dat.t)
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat.t$z)-sum(muTilde(dat.t, b)))
}, interval=c(-10, 10), tol=1e-10)$root
hat
sum(muTilde(dat.t, betaHat)*(1-muTilde(dat.t, betaHat)))
sum(muTilde(dat.t, hat)*(1-muTilde(dat.t, hat)))
# Estimates the given a data frame and a parameter beta
muTilde <- function(dat, beta) {
dat$Y1*exp(beta) / (dat$Y1*exp(beta) + dat$Y0)
}
# Returns coxph estimate and sig
betaHat <- function(dat){
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(dat, b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(dat, hat)*(1-muTilde(dat, hat)))  #what is sig?
c("coef"=betaHat, "sig"=sig)
}
betaHat(dat.t)
betaHat <- function(dat){
hat <- uniroot(function(beta) {
sapply(beta, function(b) sum(dat$z)-sum(muTilde(dat, b)))
}, interval=c(-10, 10), tol=1e-10)$root
sig <- sum(muTilde(dat, hat)*(1-muTilde(dat, hat)))  #what is sig?
c("coef"=hat, "sig"=sig)
}
betaHat(dat.t)
times <- c(0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5)
sapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
})
sapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
})
t <- 0.05
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
times <- c(0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5)
sapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
})
t <- 0.1
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
t <- 0.15
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
beta.est
times <- c(0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5)
sapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
})
apply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
})
lapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
})
t(sapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
}))
c(c(1,2),3)
c(beta.est, "time" = t)
t(sapply(times, function(t){
#censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
c(beta.est, "time" = t)
}))
mod <- coxph(Surv(obs, delta+1) ~ z, data=fulldat)
betaHat
summary(mod)$coefficients[1,"coef"]
summary(mod)$coefficients[1,"se(coef)"]
c("coef"= summary(mod)$coefficients[1,"coef"], "1/sig" = summary(mod)$coefficients[1,"se(coef)"])
cox.estimate <- function(fulldat){
mod <- coxph(Surv(obs, delta+1) ~ z, data=fulldat)
summary(mod)$coefficients[1,"se(coef)"]
c("coef"= summary(mod)$coefficients[1,"coef"], "1/sig" = summary(mod)$coefficients[1,"se(coef)"])
}
cox.estimate(dat.t)
betaHat(dat.t)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
cox.estimate(dat.t)
CPH <- function(n, invCumHaz0, rG, beta, p, Tmax, times) {
# Survival quantiles
q <- runif(n)
# We can sample survival for both arms using
# invCumHaz0. Recall that probability of surviving
# through time t is exp(-(cumulative hazard to t)),
# so survival quantile q occurs at cumulative
# hazard -log(1-q). Sampling is trivial for the
# control arm:
T0 <- invCumHaz0(-log(1-q))
# The same is true for the treatment arm -- quantile
# q is cumulative hazard -log(1-q). Since
# cumulative hazard in the treatment arm is exp(beta)
# times the cumulative hazard in the control arm,
# the time at which the treatment arm achieves
# cumulative hazard CH equals the time at which the
# control arm reaches cumulative hazard CH/exp(beta).
T1 <- invCumHaz0(-log(1-q)/exp(beta))
# Allocation to groups (z=1 means treatment)
z <- as.numeric(runif(n) < p)
TT <- ifelse(z == 1, T1, T0)
# Time in study before censoring occurs
C <- rG(n, Tmax)
# OK, let's build up a data frame with this
# information (delta indicates whether this is an
# observed event or just a censoring)
fulldat <- data.frame(obs=pmin(TT, C),
delta=as.numeric(TT <= C), z=z, C = C, TT = TT)
fulldat <- fulldat[order(fulldat$obs),]
fulldat$Y0 <- sum(1-fulldat$z) - cumsum(c(0, head(1-fulldat$z, -1)))
fulldat$Y1 <- sum(fulldat$z) - cumsum(c(0, head(fulldat$z, -1)))
# Look at observations made up to time t
effect.estimates <- t(sapply(times, function(t){
# censoring time is now either 0 (didn't enter study), or reduced by (Tmax-t) (observation period ends earlier)
C.t <- pmax(C-Tmax + t,0)
dat.t <- data.frame(obs=pmin(TT, C.t),
delta=as.numeric(TT <= C.t), z=z)
dat.t <- dat.t[order(dat.t$obs),]
dat.t$Y0 <- sum(1-dat.t$z) - cumsum(c(0, head(1-dat.t$z, -1)))
dat.t$Y1 <- sum(dat.t$z) - cumsum(c(0, head(dat.t$z, -1)))
# Can sanity check with coxph if necessary
# should match up with output of beta.est
if(FALSE){cox.estimate(dat.t)}
dat.t <- dat.t[dat.t$delta == 1,]
beta.est <- betaHat(dat.t)
c(beta.est, "time" = t)
}))
effect.estimates
}
replicate(5, CPH(n, invCumHaz0, rG, beta, p, Tmax, c(Tmax)))
as.data.frame(t(replicate(5, CPH(n, invCumHaz0, rG, beta, p, Tmax, c(Tmax)))))
as.data.frame(replicate(5, CPH(n, invCumHaz0, rG, beta, p, Tmax, c(Tmax))))
replicate(5, CPH(n, invCumHaz0, rG, beta, p, Tmax, times))
times
replicate(5, CPH(1000, invCumHaz0, rG, beta, p, Tmax, times))
Tmax
# Random sampling
n <- 100000
Tmax <- 10
invCumHaz0 <- function(CH) CH/lam
rG <- function(n, Tmax) runif(n, 0, Tmax)
sims <- as.data.frame(t(replicate(1000, CPH(n, invCumHaz0, rG, beta, p, Tmax, c(Tmax)))))
sims <- replicate(1000, CPH(n, invCumHaz0, rG, beta, p, Tmax, c(Tmax)))
sims
############################################
## Sellke and Siegmund
############################################
times <- c(1,2,3,4,5,6,7,8,9,10)
sims.SS <- replicate(1000, CPH(n, invCumHaz0, rG, beta, p, Tmax, times))
sims.AG <- sims
sims.AG.ests <- sims.AG[1, 1, 1:1000]
sims.AG.ests
hist(sims.AG.ests)
length(times)
sims.SS <- replicate(reps, CPH(n, invCumHaz0, rG, beta, p, Tmax, times))
############################################
## Andersen and Gill
############################################
# Andersen and Gill look at the effect size at
# one analysis point (T)
reps <- 1000
sims.SS <- replicate(reps, CPH(n, invCumHaz0, rG, beta, p, Tmax, times))
sims.SS.ests <- sims.SS[1:length(times), 1, 1:reps]
View(sims.SS.ests)
sims.SS.ests[2:(length(times)),1:3]-sims.SS.ests[1:(length(times)-1),1:3]
#take increments
inc <- t(sims.SS.ests[2:(length(times)),]-sims.SS.ests[1:(length(times)-1),])
View(inc)
#correlation test
pairs(inc)
corrplot(cor(inc),
method = "number",
type = "upper" # show only upper side
)
library(corrplot)
corrplot(cor(inc),
method = "number",
type = "upper" # show only upper side
)
library(Hmisc)
res <- rcorr(as.matrix(inc))
round(res$P, 3)
library(correlation)
correlation::correlation(dat,
include_factors = TRUE, method = "auto"
)
library(GGally)
ggpairs(dat[, c("mpg", "hp", "wt")])
ggpairs(inc)
library(GGally)
ggpairs(as.matrix(inc))
ggpairs(as.data.frame(inc))
sapply(1:ncol(inc), function(i){
shapiro.test(inc[i,])
})
norm.tests <- sapply(1:ncol(inc), function(i){
shapiro.test(inc[i,])
})
View(norm.tests)
ggdensity(inc[1,],
main = "Density plot of increment 1",
xlab = "difference")
ggqqplot(my_data$len)
ggqqplot(inc[1,])
norm.tests <- sapply(1:ncol(inc), function(i){
shapiro.test(inc[,i])
})
norm.tests
ggdensity(inc[,1],
main = "Density plot of increment 1",
xlab = "difference")
ggqqplot(inc[,1])
ggdensity(inc[,4],
main = "Density plot of increment 1",
xlab = "difference")
ggqqplot(inc[,4])
norm.tests <- sapply(1:ncol(inc), function(i){
shapiro.test(inc[,i])
})
ggpairs(as.data.frame(inc))
norm.tests
